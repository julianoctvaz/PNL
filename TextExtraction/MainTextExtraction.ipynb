{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MainTextExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julianoctvaz/PNL/blob/main/MainTextExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9NvjSGLRyh1",
        "outputId": "be82fe13-9a0d-4630-c56e-4c9978e89b15"
      },
      "source": [
        "#http://alexminnaar.com/2019/08/22/ner-rnns-tensorflow.html\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hppr-9dR7FA",
        "outputId": "1eb382e4-4533-454c-dccd-2ec33877f413"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/julianoctvaz/PNL/main/TextExtraction/test.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-19 22:57:02--  https://raw.githubusercontent.com/julianoctvaz/PNL/main/TextExtraction/test.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46729 (46K) [text/plain]\n",
            "Saving to: ‘test.txt’\n",
            "\n",
            "test.txt            100%[===================>]  45.63K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-07-19 22:57:02 (6.50 MB/s) - ‘test.txt’ saved [46729/46729]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v6AGlAHR9w3",
        "outputId": "82a239a0-85ae-4e3c-8ce1-60d6d441fdb9"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/julianoctvaz/PNL/main/TextExtraction/train.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-19 22:57:05--  https://raw.githubusercontent.com/julianoctvaz/PNL/main/TextExtraction/train.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 141298 (138K) [text/plain]\n",
            "Saving to: ‘train.txt’\n",
            "\n",
            "train.txt           100%[===================>] 137.99K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-07-19 22:57:05 (7.97 MB/s) - ‘train.txt’ saved [141298/141298]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12shKDvFR_Cv",
        "outputId": "fe3cd736-d618-48a9-9135-1b3c01bcf695"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/julianoctvaz/PNL/main/TextExtraction/valid.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-19 22:57:06--  https://raw.githubusercontent.com/julianoctvaz/PNL/main/TextExtraction/valid.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46020 (45K) [text/plain]\n",
            "Saving to: ‘valid.txt’\n",
            "\n",
            "\rvalid.txt             0%[                    ]       0  --.-KB/s               \rvalid.txt           100%[===================>]  44.94K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-07-19 22:57:06 (40.8 MB/s) - ‘valid.txt’ saved [46020/46020]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gP6ikxnSC-3"
      },
      "source": [
        "labels = set()\n",
        "\n",
        "def file2Examples(file_name):\n",
        "  '''\n",
        "  Read data files and return input/output pairs\n",
        "  '''\n",
        "  \n",
        "  examples=[]\n",
        "\n",
        "  with open(file_name,\"r\") as f:\n",
        "\n",
        "    next(f)\n",
        "    next(f)\n",
        "\n",
        "    example = [[],[]]\n",
        "\n",
        "    for line in f:\n",
        "      input_output_split= line.split()\n",
        "\n",
        "      if len(input_output_split)==2:\n",
        "        example[0].append(input_output_split[0])\n",
        "        example[1].append(input_output_split[-1])\n",
        "        labels.add(input_output_split[-1])\n",
        "\n",
        "      elif len(input_output_split)==0:\n",
        "        examples.append(example)\n",
        "        example=[[],[]]\n",
        "        \n",
        "      else:\n",
        "        example=[[],[]]\n",
        "\n",
        "    f.close()\n",
        "    \n",
        "    return examples\n",
        "  \n",
        "# Extract examples from train, validation, and test files which can be found at \n",
        "# https://github.com/davidsbatista/NER-datasets/tree/master/CONLL2003\n",
        "train_examples = file2Examples(\"train.txt\")\n",
        "test_examples = file2Examples(\"test.txt\")\n",
        "valid_examples = file2Examples(\"valid.txt\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNcx2mSxgSNi",
        "outputId": "f586fa4a-79b7-405d-cd78-8d232cc8b41b"
      },
      "source": [
        "!head train.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What O\n",
            "will O\n",
            "the O\n",
            "weather O\n",
            "be O\n",
            "this B-timeRange\n",
            "year I-timeRange\n",
            "in O\n",
            "Horseshoe B-geographic_poi\n",
            "Lake I-geographic_poi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2oKDCSpSHJv",
        "outputId": "16d8eeef-51be-46cf-db0d-6baffae85611"
      },
      "source": [
        "\n",
        "# create character vocab\n",
        "all_text = \" \".join([\" \".join(x[0]) for x in train_examples+valid_examples+test_examples])\n",
        "vocab = sorted(set(all_text))\n",
        "\n",
        "# create character/id and label/id mapping\n",
        "char2idx = {u:i+1 for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "label2idx = {u:i+1 for i, u in enumerate(labels)}\n",
        "idx2label = np.array(labels)\n",
        "\n",
        "print(idx2label)\n",
        "print(char2idx)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'B-condition_temperature', 'I-city', 'I-geographic_poi', 'B-timeRange', 'B-condition_description', 'B-current_location', 'O', 'I-timeRange', 'B-state', 'B-city', 'I-state', 'I-spatial_relation', 'B-spatial_relation', 'I-country', 'B-geographic_poi', 'B-country', 'I-current_location'}\n",
            "{' ': 1, '0': 2, '1': 3, '2': 4, '3': 5, '4': 6, '5': 7, '6': 8, '7': 9, '8': 10, '9': 11, 'A': 12, 'B': 13, 'C': 14, 'D': 15, 'E': 16, 'F': 17, 'G': 18, 'H': 19, 'I': 20, 'J': 21, 'K': 22, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'Q': 28, 'R': 29, 'S': 30, 'T': 31, 'U': 32, 'V': 33, 'W': 34, 'X': 35, 'Y': 36, 'Z': 37, 'a': 38, 'b': 39, 'c': 40, 'd': 41, 'e': 42, 'f': 43, 'g': 44, 'h': 45, 'i': 46, 'j': 47, 'k': 48, 'l': 49, 'm': 50, 'n': 51, 'o': 52, 'p': 53, 'q': 54, 'r': 55, 's': 56, 't': 57, 'u': 58, 'v': 59, 'w': 60, 'x': 61, 'y': 62, 'z': 63}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UrNiL6agNcy",
        "outputId": "04c83013-ab3e-48fb-ee94-1fc3e50cb81f"
      },
      "source": [
        "def split_char_labels(eg):\n",
        "  '''\n",
        "  For a given input/output example, break tokens into characters while keeping \n",
        "  the same label.\n",
        "  '''\n",
        "\n",
        "  tokens = eg[0]\n",
        "  labels=eg[1]\n",
        "\n",
        "  input_chars = []\n",
        "  output_char_labels = []\n",
        "\n",
        "  for token,label in zip(tokens,labels):\n",
        "\n",
        "    input_chars.extend([char for char in token])\n",
        "    input_chars.extend(' ')\n",
        "    output_char_labels.extend([label]*len(token))\n",
        "    output_char_labels.extend('O')\n",
        "\n",
        "  return [[char2idx[x] for x in input_chars[:-1]],np.array([label2idx[x] for x in output_char_labels[:-1]])]\n",
        "\n",
        "train_formatted = [split_char_labels(eg) for eg in train_examples]\n",
        "test_formatted = [split_char_labels(eg) for eg in test_examples]\n",
        "valid_formatted = [split_char_labels(eg) for eg in valid_examples]\n",
        "\n",
        "print(len(train_formatted))\n",
        "print(len(test_formatted))\n",
        "print(len(valid_formatted))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200\n",
            "400\n",
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uF72cAG_8CY",
        "outputId": "9d4f6cb1-12da-46fa-9dfd-4eaf14e6134c"
      },
      "source": [
        " #training generator\n",
        "def gen_train_series():\n",
        "  for eg in train_formatted:\n",
        "     yield eg[0],eg[1]\n",
        "\n",
        "# validation generator\n",
        "def gen_valid_series():\n",
        "  for eg in valid_formatted:\n",
        "     yield eg[0],eg[1]\n",
        "\n",
        "# test generator\n",
        "def gen_test_series():\n",
        "  for eg in test_formatted:\n",
        "      yield eg[0],eg[1]\n",
        "      \n",
        "# create Dataset objects for train, test and validation sets  \n",
        "series = tf.data.Dataset.from_generator(gen_train_series,output_types=(tf.int32, tf.int32),output_shapes = ((None, None)))\n",
        "series_valid = tf.data.Dataset.from_generator(gen_valid_series,output_types=(tf.int32, tf.int32),output_shapes = ((None, None)))\n",
        "series_test = tf.data.Dataset.from_generator(gen_test_series,output_types=(tf.int32, tf.int32),output_shapes = ((None, None)))\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "BUFFER_SIZE=1000\n",
        "\n",
        "# create padded batch series objects for train, test and validation sets\n",
        "ds_series_batch = series.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE, padded_shapes=([None], [None]), drop_remainder=True)\n",
        "ds_series_batch_valid = series_valid.padded_batch(BATCH_SIZE, padded_shapes=([None], [None]), drop_remainder=True)\n",
        "ds_series_batch_test = series_test.padded_batch(BATCH_SIZE, padded_shapes=([None], [None]), drop_remainder=True)\n",
        "  \n",
        "  # print example batches\n",
        "for input_example_batch, target_example_batch in ds_series_batch_valid.take(1):\n",
        "  print(input_example_batch)\n",
        "  print(target_example_batch)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[43 55 42 ...  0  0  0]\n",
            " [34 46 49 ...  0  0  0]\n",
            " [34 45 38 ...  0  0  0]\n",
            " ...\n",
            " [31 42 49 ...  0  0  0]\n",
            " [34 46 49 ...  0  0  0]\n",
            " [31 42 49 ...  0  0  0]], shape=(128, 110), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [7 7 7 ... 0 0 0]\n",
            " [7 7 7 ... 0 0 0]\n",
            " ...\n",
            " [7 7 7 ... 0 0 0]\n",
            " [7 7 7 ... 0 0 0]\n",
            " [7 7 7 ... 0 0 0]], shape=(128, 110), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBLlZRRKBRXG",
        "outputId": "f7643847-3bfd-4af7-a6ec-96577e48459c"
      },
      "source": [
        "vocab_size = len(vocab)+1\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n",
        "\n",
        "label_size = len(labels)  \n",
        "\n",
        "# build LSTM model\n",
        "def build_model(vocab_size,label_size, embedding_dim, rnn_units, batch_size):\n",
        "      model = tf.keras.Sequential([\n",
        "          tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                            batch_input_shape=[batch_size, None],mask_zero=True),\n",
        "          tf.keras.layers.LSTM(rnn_units,\n",
        "                      return_sequences=True,\n",
        "                      stateful=True,\n",
        "                      recurrent_initializer='glorot_uniform'),\n",
        "          tf.keras.layers.Dense(label_size)\n",
        "          ])\n",
        "      return model\n",
        "\n",
        "model = build_model(\n",
        "      vocab_size = len(vocab)+1,\n",
        "      label_size=len(labels)+1,\n",
        "      embedding_dim=embedding_dim,\n",
        "      rnn_units=rnn_units,\n",
        "      batch_size=BATCH_SIZE)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 256)          16384     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (128, None, 1024)         5246976   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 18)           18450     \n",
            "=================================================================\n",
            "Total params: 5,281,810\n",
            "Trainable params: 5,281,810\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMYKcpuABnRj"
      },
      "source": [
        "import os\n",
        "\n",
        "# define loss function\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer='adam', loss=loss,metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8ygo-BsBr6v",
        "outputId": "2a109402-9494-40db-b2ac-b231a200a920"
      },
      "source": [
        "EPOCHS=20\n",
        "\n",
        "history = model.fit(ds_series_batch, epochs=EPOCHS, validation_data=ds_series_batch_valid,callbacks=[checkpoint_callback])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "9/9 [==============================] - 114s 12s/step - loss: 1.1897 - sparse_categorical_accuracy: 0.5041 - val_loss: 0.9677 - val_sparse_categorical_accuracy: 0.5763\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 122s 14s/step - loss: 0.8972 - sparse_categorical_accuracy: 0.5659 - val_loss: 0.7806 - val_sparse_categorical_accuracy: 0.5763\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 112s 12s/step - loss: 0.8272 - sparse_categorical_accuracy: 0.5646 - val_loss: 0.7456 - val_sparse_categorical_accuracy: 0.5763\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 110s 12s/step - loss: 0.8469 - sparse_categorical_accuracy: 0.5508 - val_loss: 0.7335 - val_sparse_categorical_accuracy: 0.5762\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 111s 12s/step - loss: 0.7781 - sparse_categorical_accuracy: 0.5677 - val_loss: 0.7031 - val_sparse_categorical_accuracy: 0.5817\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 113s 13s/step - loss: 0.7392 - sparse_categorical_accuracy: 0.5805 - val_loss: 0.6830 - val_sparse_categorical_accuracy: 0.6152\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 111s 12s/step - loss: 0.7068 - sparse_categorical_accuracy: 0.6022 - val_loss: 0.6687 - val_sparse_categorical_accuracy: 0.5967\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 111s 12s/step - loss: 0.6833 - sparse_categorical_accuracy: 0.6042 - val_loss: 0.6291 - val_sparse_categorical_accuracy: 0.6260\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 106s 12s/step - loss: 0.6714 - sparse_categorical_accuracy: 0.6166 - val_loss: 0.5875 - val_sparse_categorical_accuracy: 0.6269\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 107s 12s/step - loss: 0.6465 - sparse_categorical_accuracy: 0.6181 - val_loss: 0.5908 - val_sparse_categorical_accuracy: 0.6417\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 108s 12s/step - loss: 0.6270 - sparse_categorical_accuracy: 0.6354 - val_loss: 0.5833 - val_sparse_categorical_accuracy: 0.6348\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 108s 12s/step - loss: 0.6090 - sparse_categorical_accuracy: 0.6345 - val_loss: 0.5488 - val_sparse_categorical_accuracy: 0.6474\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 108s 12s/step - loss: 0.7013 - sparse_categorical_accuracy: 0.6071 - val_loss: 0.8186 - val_sparse_categorical_accuracy: 0.5946\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 111s 12s/step - loss: 0.6534 - sparse_categorical_accuracy: 0.6180 - val_loss: 0.5485 - val_sparse_categorical_accuracy: 0.6452\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 108s 12s/step - loss: 0.5840 - sparse_categorical_accuracy: 0.6432 - val_loss: 0.5414 - val_sparse_categorical_accuracy: 0.6546\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 105s 12s/step - loss: 0.5759 - sparse_categorical_accuracy: 0.6584 - val_loss: 0.5173 - val_sparse_categorical_accuracy: 0.6562\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 107s 12s/step - loss: 0.5476 - sparse_categorical_accuracy: 0.6624 - val_loss: 0.5040 - val_sparse_categorical_accuracy: 0.6644\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 111s 12s/step - loss: 0.5107 - sparse_categorical_accuracy: 0.6727 - val_loss: 0.4974 - val_sparse_categorical_accuracy: 0.6698\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 110s 12s/step - loss: 0.5115 - sparse_categorical_accuracy: 0.6830 - val_loss: 0.4860 - val_sparse_categorical_accuracy: 0.6806\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 110s 12s/step - loss: 0.4998 - sparse_categorical_accuracy: 0.6887 - val_loss: 0.4862 - val_sparse_categorical_accuracy: 0.6716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljnS6g2tL4rJ",
        "outputId": "a074d3ee-49a5-409e-dc8b-0750073132f4"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "preds = np.array([])\n",
        "y_trues= np.array([])\n",
        "\n",
        "# iterate through test set, make predictions based on trained model\n",
        "for input_example_batch, target_example_batch in ds_series_batch_test:\n",
        "\n",
        "  pred=model.predict_on_batch(input_example_batch)\n",
        "  pred_max=tf.argmax(tf.nn.softmax(pred),2).numpy().flatten()\n",
        "  y_true=target_example_batch.numpy().flatten()\n",
        "\n",
        "  preds=np.concatenate([preds,pred_max])\n",
        "  y_trues=np.concatenate([y_trues,y_true])\n",
        "\n",
        "# remove padding from evaluation\n",
        "remove_padding = [(p,y) for p,y in zip(preds,y_trues) if y!=0]\n",
        "\n",
        "r_p = [x[0] for x in remove_padding]\n",
        "r_t = [x[1] for x in remove_padding]\n",
        "\n",
        "# print confusion matrix and classification report\n",
        "print(confusion_matrix(r_p,r_t))\n",
        "print(classification_report(r_p,r_t))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  98    0    0    2   18    2   82    1    0    0    0    0    0    0\n",
            "     0    0    0]\n",
            " [   0  212  423    6    0    0   84   21   94   23   43    0    0  148\n",
            "    39  151    0]\n",
            " [   0    0  229    2    0    0   13    3    3    0    6    0    0   11\n",
            "     0    0    0]\n",
            " [   0    0   28   48    4    0   33   24    6   14    0    2    7    6\n",
            "     0    3    0]\n",
            " [  43    5    2   14  158    1   76    1    2    1    0    1    0    0\n",
            "     2    0    0]\n",
            " [  32    0    0   14   18   90   42   38    0    0    0    0    2    0\n",
            "     0    0    0]\n",
            " [ 354   45  340  434  308   78 9688  330   52  156   28   94  172   62\n",
            "    31   46    5]\n",
            " [   2    0    0  161   10   40  233  885    3   14    0   12   19    0\n",
            "     0    0    2]\n",
            " [   0    0    1    0    1    0    5    3   21    1    3    0    0    9\n",
            "     0    1    0]\n",
            " [   0   60   83   99    3    0   97   32  227  957   14   17    0   26\n",
            "   247  382    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]\n",
            " [   0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
            "     0    1    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0]\n",
            " [   0    0    8    0    0    0    8    0    0    0    0    0    0    9\n",
            "     0    4    0]\n",
            " [   0    0    0    1    4    0   27   14    0    0    0    1   10    0\n",
            "     0    0   92]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.19      0.48      0.27       203\n",
            "         2.0       0.66      0.17      0.27      1244\n",
            "         3.0       0.21      0.86      0.33       267\n",
            "         4.0       0.06      0.27      0.10       175\n",
            "         5.0       0.30      0.52      0.38       306\n",
            "         6.0       0.43      0.38      0.40       236\n",
            "         7.0       0.93      0.79      0.86     12223\n",
            "         8.0       0.65      0.64      0.65      1381\n",
            "         9.0       0.05      0.47      0.09        45\n",
            "        10.0       0.82      0.43      0.56      2244\n",
            "        11.0       0.00      0.00      0.00         0\n",
            "        12.0       0.00      0.00      0.00         0\n",
            "        13.0       0.00      0.00      0.00         0\n",
            "        14.0       0.00      0.00      0.00         2\n",
            "        15.0       0.00      0.00      0.00         0\n",
            "        16.0       0.01      0.14      0.01        29\n",
            "        17.0       0.93      0.62      0.74       149\n",
            "\n",
            "    accuracy                           0.67     18504\n",
            "   macro avg       0.31      0.34      0.27     18504\n",
            "weighted avg       0.83      0.67      0.73     18504\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}